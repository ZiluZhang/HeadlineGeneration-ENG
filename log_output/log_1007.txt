Using TensorFlow backend.
  0%|          | 0/142463 [00:00<?, ?it/s] 94%|#########3| 133560/142463 [00:00<00:00, 1335588.54it/s]100%|##########| 142463/142463 [00:00<00:00, 1343951.95it/s]
2017-10-07 13:43:05.264152: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-07 13:43:05.264195: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-07 13:43:05.264205: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-07 13:43:05.264213: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-07 13:43:05.264222: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
model options {'validFreq': 10, 'batch_size': 100, 'dim_proj': 300, 'mode': 'train', 'valid_batch_size': 100, 'max_epochs': 1}
Loading data
vocab_size = 163540
id2v.shape = (163540, 300)
Building model
model done
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 210)           0                                            
____________________________________________________________________________________________________
embedding_1 (Embedding)          (None, 210, 300)      49062000    input_1[0][0]                    
____________________________________________________________________________________________________
reshape_1 (Reshape)              (None, 7, 30, 300)    0           embedding_1[0][0]                
____________________________________________________________________________________________________
time_distributed_1 (TimeDistribu (None, 7, 30, 600)    1081800     reshape_1[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 7, 30, 300)    180300      time_distributed_1[0][0]         
____________________________________________________________________________________________________
input_2 (InputLayer)             (None, 15)            0                                            
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 7, 300)        0           dense_1[0][0]                    
____________________________________________________________________________________________________
embedding_2 (Embedding)          (None, 15, 300)       49062000    input_2[0][0]                    
____________________________________________________________________________________________________
gru_2 (GRU)                      (None, 7, 300)        540900      lambda_1[0][0]                   
____________________________________________________________________________________________________
attention_2h_gru_1 (Attention_2H (None, 15, 300)       1352702     embedding_2[0][0]                
                                                                   gru_2[0][0]                      
                                                                   dense_1[0][0]                    
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 15, 163540)    49225540    attention_2h_gru_1[0][0]         
====================================================================================================
Total params: 150,505,242
Trainable params: 52,381,242
Non-trainable params: 98,124,000
____________________________________________________________________________________________________
113971 train examples
14246 valid examples
14246 test examples
Block 0/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 364s - loss: 12.0027 200/1000 [=====>........................] - ETA: 301s - loss: 11.8980 300/1000 [========>.....................] - ETA: 253s - loss: 11.6219 400/1000 [===========>..................] - ETA: 215s - loss: 11.2911 500/1000 [==============>...............] - ETA: 176s - loss: 10.9608 600/1000 [=================>............] - ETA: 139s - loss: 10.6434 700/1000 [====================>.........] - ETA: 103s - loss: 10.3271 800/1000 [=======================>......] - ETA: 68s - loss: 10.0581  900/1000 [==========================>...] - ETA: 34s - loss: 9.8069 1000/1000 [==============================] - 355s - loss: 9.6203 - val_loss: 8.0244/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/keras/engine/topology.py:2341: UserWarning: Layer attention_2h_gru_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'dense_3/BiasAdd:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).
  str(node.arguments) + '. They will not be included '

Block 1/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 282s - loss: 7.8524 200/1000 [=====>........................] - ETA: 256s - loss: 7.6844 300/1000 [========>.....................] - ETA: 222s - loss: 7.7403 400/1000 [===========>..................] - ETA: 191s - loss: 7.6690 500/1000 [==============>...............] - ETA: 159s - loss: 7.6472 600/1000 [=================>............] - ETA: 127s - loss: 7.7141 700/1000 [====================>.........] - ETA: 95s - loss: 7.6783  800/1000 [=======================>......] - ETA: 63s - loss: 7.7039 900/1000 [==========================>...] - ETA: 31s - loss: 7.67921000/1000 [==============================] - 334s - loss: 7.6718 - val_loss: 7.7977
Block 2/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 280s - loss: 7.2032 200/1000 [=====>........................] - ETA: 255s - loss: 7.3236 300/1000 [========>.....................] - ETA: 220s - loss: 7.4827 400/1000 [===========>..................] - ETA: 190s - loss: 7.4103 500/1000 [==============>...............] - ETA: 157s - loss: 7.3635 600/1000 [=================>............] - ETA: 126s - loss: 7.3903 700/1000 [====================>.........] - ETA: 94s - loss: 7.3799  800/1000 [=======================>......] - ETA: 63s - loss: 7.3959 900/1000 [==========================>...] - ETA: 31s - loss: 7.42901000/1000 [==============================] - 332s - loss: 7.4176 - val_loss: 7.6211
Block 3/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 279s - loss: 7.4236 200/1000 [=====>........................] - ETA: 253s - loss: 7.3785 300/1000 [========>.....................] - ETA: 220s - loss: 7.3403 400/1000 [===========>..................] - ETA: 190s - loss: 7.3990 500/1000 [==============>...............] - ETA: 157s - loss: 7.4031 600/1000 [=================>............] - ETA: 127s - loss: 7.3726 700/1000 [====================>.........] - ETA: 94s - loss: 7.4129  800/1000 [=======================>......] - ETA: 63s - loss: 7.3590 900/1000 [==========================>...] - ETA: 31s - loss: 7.35571000/1000 [==============================] - 333s - loss: 7.3403 - val_loss: 7.3803
Block 4/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 277s - loss: 7.0837 200/1000 [=====>........................] - ETA: 251s - loss: 7.0660 300/1000 [========>.....................] - ETA: 220s - loss: 7.0963 400/1000 [===========>..................] - ETA: 189s - loss: 7.0216 500/1000 [==============>...............] - ETA: 157s - loss: 6.9529 600/1000 [=================>............] - ETA: 126s - loss: 6.9336 700/1000 [====================>.........] - ETA: 94s - loss: 6.9951  800/1000 [=======================>......] - ETA: 63s - loss: 6.9657 900/1000 [==========================>...] - ETA: 31s - loss: 6.93131000/1000 [==============================] - 330s - loss: 6.9655 - val_loss: 6.7883
Block 5/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 285s - loss: 6.6888 200/1000 [=====>........................] - ETA: 257s - loss: 6.8996 300/1000 [========>.....................] - ETA: 224s - loss: 6.9292 400/1000 [===========>..................] - ETA: 192s - loss: 6.9717 500/1000 [==============>...............] - ETA: 159s - loss: 6.9890 600/1000 [=================>............] - ETA: 128s - loss: 7.0338 700/1000 [====================>.........] - ETA: 96s - loss: 7.0734  800/1000 [=======================>......] - ETA: 64s - loss: 7.0566 900/1000 [==========================>...] - ETA: 32s - loss: 7.06381000/1000 [==============================] - 338s - loss: 7.0735 - val_loss: 6.8928
Block 6/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 283s - loss: 7.3668 200/1000 [=====>........................] - ETA: 262s - loss: 7.2358 300/1000 [========>.....................] - ETA: 238s - loss: 7.2107 400/1000 [===========>..................] - ETA: 207s - loss: 7.0767 500/1000 [==============>...............] - ETA: 172s - loss: 7.1000 600/1000 [=================>............] - ETA: 138s - loss: 7.0484 700/1000 [====================>.........] - ETA: 103s - loss: 7.0723 800/1000 [=======================>......] - ETA: 69s - loss: 7.0791  900/1000 [==========================>...] - ETA: 34s - loss: 7.05141000/1000 [==============================] - 399s - loss: 7.0695 - val_loss: 7.1351
Block 7/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 278s - loss: 7.0008 200/1000 [=====>........................] - ETA: 247s - loss: 7.0617 300/1000 [========>.....................] - ETA: 217s - loss: 6.9993 400/1000 [===========>..................] - ETA: 186s - loss: 7.1314 500/1000 [==============>...............] - ETA: 155s - loss: 7.1813 600/1000 [=================>............] - ETA: 125s - loss: 7.2611 700/1000 [====================>.........] - ETA: 94s - loss: 7.2865  800/1000 [=======================>......] - ETA: 64s - loss: 7.3032 900/1000 [==========================>...] - ETA: 32s - loss: 7.25951000/1000 [==============================] - 363s - loss: 7.2623 - val_loss: 7.0516
Block 8/113
Train on 1000 samples, validate on 126 samples
Epoch 1/1
 100/1000 [==>...........................] - ETA: 279s - loss: 6.7239 200/1000 [=====>........................] - ETA: 254s - loss: 6.9076 300/1000 [========>.....................] - ETA: 225s - loss: 7.0079 400/1000 [===========>..................] - ETA: 205s - loss: 7.0527 500/1000 [==============>...............] - ETA: 192s - loss: 7.0119 600/1000 [=================>............] - ETA: 152s - loss: 6.9764 700/1000 [====================>.........] - ETA: 111s - loss: 6.9887Traceback (most recent call last):
  File "Paper-model-main.py", line 272, in <module>
    train_lstm(**args)
  File "Paper-model-main.py", line 138, in train_lstm
    epochs=1)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/keras/engine/training.py", line 1598, in fit
    validation_steps=validation_steps)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/keras/engine/training.py", line 1183, in _fit_loop
    outs = f(ins_batch)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2273, in __call__
    **self.session_kwargs)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1327, in _do_call
    return fn(*args)
  File "/home/zm/zhangzilu/eng_headline/zzlenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1306, in _run_fn
    status, run_metadata)
KeyboardInterrupt
